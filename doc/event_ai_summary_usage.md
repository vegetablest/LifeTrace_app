# 事件AI智能摘要使用指南

## 功能概述

事件AI智能摘要功能能够自动为每个完成的事件生成简洁的标题和描述性摘要，帮助用户快速了解历史活动内容。

## 自动生成

### 工作原理

1. **自动触发**：当你切换应用时，前一个应用的事件会自动关闭，系统会在后台自动生成该事件的AI摘要
2. **OCR分析**：系统收集该事件中所有截图的OCR文本内容
3. **AI生成**：使用大语言模型分析文本，生成10字以内的标题和30字以内的摘要
4. **前端展示**：在"忆往昔"面板中，优先显示AI生成的标题和摘要

### 无需任何操作

功能完全自动运行，无需用户干预：
- ✅ 自动识别事件结束
- ✅ 自动收集OCR数据
- ✅ 自动生成摘要
- ✅ 自动更新显示

## 查看效果

### 在忆往昔面板查看

1. 打开LifeTrace应用
2. 点击左侧导航栏的"忆往昔"图标（历史记录）
3. 浏览事件列表

**传统显示方式：**
```
标题：LifeTrace - Chrome
描述：应用: chrome.exe
     正在进行的活动记录和截图捕捉
```

**AI摘要显示方式：**
```
标题：浏览项目文档
描述：阅读**LifeTrace**的事件机制说明和API文档
```

### 摘要特点

- **标题简洁**：不超过10个字，直接点明核心活动
- **描述清晰**：不超过30个字，突出关键信息
- **重点标粗**：重要内容使用粗体显示，一目了然

## 手动触发生成

### 通过API手动生成

如果某个事件没有生成摘要，或者想要重新生成，可以使用API：

```bash
# 为事件ID为123的事件生成摘要
curl -X POST http://localhost:5000/api/events/123/generate-summary
```

响应示例：
```json
{
  "success": true,
  "event_id": 123,
  "ai_title": "编写代码",
  "ai_summary": "在**VS Code**中开发Python脚本"
}
```

## 批量处理历史数据

### 查看统计信息

```bash
python -m lifetrace_backend.event_summary_commands stats
```

输出示例：
```
事件摘要统计
总事件数: 1250
已结束事件: 1180
已生成摘要: 850
需要生成摘要: 330
摘要覆盖率: 72.0%
```

### 批量生成摘要

**为所有未生成摘要的历史事件生成：**
```bash
python -m lifetrace_backend.event_summary_commands generate-summaries
```

**强制重新生成所有事件的摘要：**
```bash
python -m lifetrace_backend.event_summary_commands generate-summaries --force
```

**限制处理数量（处理最近的100个事件）：**
```bash
python -m lifetrace_backend.event_summary_commands generate-summaries --limit 100
```

### 批量处理输出示例

```
开始批量生成事件摘要
强制重新生成: False
处理数量限制: 无限制
找到 330 个需要处理的事件

[1/330] 处理事件 ID=456, 应用=chrome.exe, 时间=2025-10-11 14:30:00
  ✓ 成功生成摘要
[2/330] 处理事件 ID=455, 应用=code.exe, 时间=2025-10-11 13:15:00
  ✓ 成功生成摘要
...

批量生成完成
总计: 330 个事件
成功: 325 个
失败: 5 个
成功率: 98.5%
```

## 技术说明

### LLM模型

**当前使用：** 阿里通义千问（Qwen3-Max）

**模型配置：**
- API地址：`https://dashscope.aliyuncs.com/compatible-mode/v1`
- 温度参数：0.3（较低，保证输出稳定性）
- 最大令牌：200

### 后备方案

如果OCR数据不足或LLM不可用，系统会自动使用后备方案：
- 基于应用名称生成简单标题，如："Chrome使用"
- 基于应用名和窗口标题生成描述，如："使用**Chrome**中活动"

### 性能优化

- **异步处理**：摘要生成在后台线程中进行，不影响截图录制性能
- **增量更新**：只处理新完成的事件，避免重复计算
- **智能限流**：OCR文本限制为3000字符，避免token超限

## 常见问题

### Q: 为什么有些事件没有AI摘要？

A: 可能的原因：
1. 事件刚刚结束，摘要正在后台生成中（通常需要2-5秒）
2. 事件是在功能上线前创建的（可以使用批量生成工具补充）
3. OCR处理尚未完成（需要等待OCR服务处理）
4. LLM服务暂时不可用（会显示后备方案生成的简单描述）

### Q: 如何判断摘要是AI生成的还是后备方案？

A:
- **AI生成**：标题简洁且语义化（如"编写代码"、"浏览文档"），摘要有粗体标记
- **后备方案**：标题通常是"应用名+使用"（如"Chrome使用"），描述较为通用

### Q: 摘要生成会消耗多少资源？

A:
- **CPU**：几乎无影响（异步处理）
- **内存**：每次生成约消耗10-20MB，处理完成后释放
- **网络**：每次API调用约1-3KB请求+1KB响应
- **API费用**：使用阿里云通义千问，每次约0.001-0.003元

### Q: 可以关闭这个功能吗？

A: 目前功能是自动开启的。如需关闭，可以修改 `lifetrace_backend/storage.py` 中的 `get_or_create_event()` 方法，注释掉触发摘要生成的代码（第203-208行）。

### Q: 摘要不准确怎么办？

A:
1. 使用手动触发API重新生成：`POST /api/events/{event_id}/generate-summary`
2. 检查OCR质量：摘要质量取决于OCR识别的准确性
3. 反馈问题：收集不准确的案例，用于优化prompt

## 最佳实践

### 提高摘要质量

1. **确保OCR及时处理**：摘要依赖OCR结果，定期检查OCR处理状态
2. **合理的事件粒度**：避免在同一应用中停留时间过长，适当切换应用可以产生更精确的事件
3. **清晰的窗口标题**：应用的窗口标题会作为上下文提供给LLM，有助于生成更准确的摘要

### 批量处理建议

1. **首次使用**：先运行 `stats` 查看需要处理的数量
2. **分批处理**：如果数量很大（>1000），使用 `--limit` 参数分批处理
3. **错峰处理**：批量生成会调用大量API，建议在非工作时间运行
4. **监控日志**：批量处理时注意查看日志，及时发现和解决问题

## 未来改进

- [ ] 支持多语言摘要（根据OCR内容语言自动选择）
- [ ] 支持自定义prompt模板
- [ ] 支持本地LLM模型（降低API成本）
- [ ] 添加摘要质量评分和用户反馈机制
- [ ] 支持事件标签自动生成

---

**文档版本：** 1.0  
**创建日期：** 2025-10-11  
**适用版本：** LifeTrace v1.1+
